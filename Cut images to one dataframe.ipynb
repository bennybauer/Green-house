{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook iterate pickle files calculated from the cut-images script. it calculates the mean and std per plant per date per time if it has radiance below the white reference panel. \n",
    "The script takes the mean of the 80% highest albedo pixel per plant.\n",
    "albedo is calculated as the mean across the entire spectral range 400-1000 nm.\n",
    "There is an additional step which is commented out that can check across the spectrum for values above 1 and below 0 and exclude entire spectra which have such values. however this causes loss of many pixel since many of this variations are caused because of water absorption bands. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Works fine but slow to load df to memory - not any more\n",
    "\"\"\"\n",
    "path = r'D:\\DONE'\n",
    "file_list = files = [os.path.join(dirpath, f)\n",
    "    for dirpath, dirnames, files in os.walk(path)\n",
    "        for f in files if f.endswith('pickle')]\n",
    "collector = {}\n",
    "for file in file_list:\n",
    "    print (file)\n",
    "    df = pd.read_pickle(file) # read pickle file\n",
    "    spectralon = df[df['name']=='spectralon'].iloc[:,5:] #get spectralon radiance\n",
    "    df_rad = df[df.type=='rad'] #just radiance\n",
    "    df_rad = df_rad[:-2].copy() #drop spectralon and black\n",
    "    df_rad.reset_index(drop=True, inplace = True) #reset index to match reflectance\n",
    "    print (df_rad['name'].unique())\n",
    "    df_ref = df[df.type=='ref'] #just reflectance\n",
    "    df_rad = df_rad[:-2].copy()\n",
    "    df_ref.reset_index(drop=True, inplace = True) #reset index to match rad\n",
    "    print (df_rad['name'].unique())\n",
    "    a = df_rad.iloc[:,2].where(((df_rad.iloc[:,5:].values<spectralon.values).sum(axis=1))==448).index.values #select pixels which are under the spectralon\n",
    "    df = df_ref.iloc[a].copy() #select the pixels for analysis\n",
    "    df.name = df.name.cat.remove_unused_categories()\n",
    "    print (df['name'].unique())\n",
    "#     df = df[df.type=='ref'] #keep only reflectance\n",
    "#     df.reset_index(drop=True, inplace = True) #reindex\n",
    "    df.drop(columns = ['coord'],inplace=True) # don't need coord anymore\n",
    "    df = df.drop_duplicates() #drop duplicates \n",
    "    df['albedo'] = df.iloc[:,5:].mean(axis=1) #make albedo column\n",
    "    cols = df.columns.tolist() # columns list\n",
    "    df = df[[cols[-1]] + cols[:-1]] # bring albedo column to first\n",
    "    names_count = df.name.value_counts() #how many pixels per plant\n",
    "    count_80_prcnt = np.round(0.8*names_count).astype(int).copy() #how many pixels is 80%\n",
    "    mean_spec = {} #mean spectrum holder\n",
    "    std_spec = {}\n",
    "    idx_80_prcnt = {} #index of 80%\n",
    "    for i,j in count_80_prcnt.iteritems(): # e.g 13D     4687\n",
    "        print (i)\n",
    "        idx_80_prcnt[i] = df['albedo'][df['name'] == i].sort_values(ascending=False).iloc[:j].index\n",
    "#         a = df[df['name']==i].loc[idx_80_prcnt[i]].iloc[:,5:]\n",
    "#         a.loc[((a.loc[:,:]>0) & (a.loc[:,:]<1)).sum(axis=1)==448] #0,1,448 strong threshold\n",
    "        mean_spec[i] = df[df['name']==i].loc[idx_80_prcnt[i]].iloc[:,5:].mean(axis=0)\n",
    "        std_spec[i] = df[df['name']==i].loc[idx_80_prcnt[i]].iloc[:,5:].std(axis=0)\n",
    "    collector[file[-26:-7]] = [mean_spec, std_spec]     \n",
    "winsound.PlaySound('sound.wav', winsound.SND_FILENAME)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=[]\n",
    "for key in collector:\n",
    "    a = pd.DataFrame(collector[key][0]).T\n",
    "    b = pd.DataFrame(collector[key][1]).T\n",
    "    a['time'] = ['2018-09-19_07-05-57' for i in range(a.shape[0])]\n",
    "    a['type'] = 'MEAN'\n",
    "    b['type'] = 'STD'\n",
    "    b['time'] = ['2018-09-19_07-05-57' for i in range(a.shape[0])]\n",
    "    a.time = pd.to_datetime(a.time,format='%Y-%m-%d_%H-%M-%S')\n",
    "    b.time = pd.to_datetime(a.time,format='%Y-%m-%d_%H-%M-%S')\n",
    "    a = a.set_index(['time','type'], append=True)\n",
    "    b = b.set_index(['time','type'], append=True)\n",
    "    c.append(a.append(b))\n",
    "df = pd.concat(c)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(r'D:\\DONE\\combined')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
